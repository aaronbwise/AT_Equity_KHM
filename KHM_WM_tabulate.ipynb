{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alive & Thrive\n",
    "## Cambodia Data: Women Files - Tabulation\n",
    "## Prepared by Aaron Wise; aaron@a3di.dev\n",
    "### Version: 12 November 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1500)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate_vars import (\n",
    "    read_csv_file,\n",
    "    concatenate_dfs,\n",
    "    save_combined,\n",
    "    create_bivariate_var_dep,\n",
    "    extract_regression_params\n",
    ")\n",
    "\n",
    "from aw_analytics import mean_wt, output_mean_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save combined women's file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file -- KHM_women_2000_working.csv -- has the following shape: Rows: 3210; Columns: 20\n",
      "The file -- KHM_women_2005_working.csv -- has the following shape: Rows: 3268; Columns: 27\n",
      "The file -- KHM_women_2010_working.csv -- has the following shape: Rows: 3215; Columns: 27\n",
      "The file -- KHM_women_2014_working.csv -- has the following shape: Rows: 2899; Columns: 24\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "country = 'KHM'\n",
    "recode = 'women'\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "year_list = ['2000', '2005', '2010', '2014'] \n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Read in files, store dfs in list\n",
    "list_of_dfs = [read_csv_file(country, recode, year, file_type='working') for year in year_list]\n",
    "\n",
    "# Combine the dfs\n",
    "df = concatenate_dfs(list_of_dfs)\n",
    "\n",
    "# Save and export\n",
    "save_combined(df, country, recode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Year').region.value_counts(dropna=False).sort_index().to_csv('region_by_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file -- KHM_women_2000_working.csv -- has the following shape: Rows: 3210; Columns: 20\n",
      "Warning: Unable to create sheet for var pnc_mother\n",
      "The file -- KHM_women_2005_working.csv -- has the following shape: Rows: 3268; Columns: 27\n",
      "The file -- KHM_women_2010_working.csv -- has the following shape: Rows: 3215; Columns: 27\n",
      "The file -- KHM_women_2014_working.csv -- has the following shape: Rows: 2899; Columns: 24\n"
     ]
    }
   ],
   "source": [
    "## TOTAL DATASET\n",
    "\n",
    "# Set parameters\n",
    "vars = ['anc_4_visits', 'anc_3_components', 'inst_delivery', 'caesarean_del', 'pnc_mother', 'low_bw', 'early_bf', 'iron_supp'] \n",
    "\n",
    "ind_vars = ['Total', 'residence', 'region', 'mother_edu', 'wealth_q', 'elderly_hoh', 'sex_hoh']\n",
    "\n",
    "wt = 'wmweight'\n",
    "\n",
    "# Run for loop\n",
    "\n",
    "for year in year_list:\n",
    "\n",
    "    df = read_csv_file(country, recode, year, file_type='working')\n",
    "\n",
    "    out_fn = country + \"_\" + recode + \"_\" + year + \".xlsx\"\n",
    "    path = Path.cwd() / 'output' / 'frequencies' / recode / out_fn\n",
    "    \n",
    "    # Instantiate object\n",
    "    xlwriter = pd.ExcelWriter(path)\n",
    "    \n",
    "    for var in vars:\n",
    "\n",
    "        try:\n",
    "            output = output_mean_table(df.dropna(subset=[var]), var, ind_vars, wt)\n",
    "            sheet_name = str(var) + '_weighted'\n",
    "            output.to_excel(xlwriter, sheet_name=sheet_name)\n",
    "        \n",
    "        except:\n",
    "            print(f\"Warning: Unable to create sheet for var {var}\")\n",
    "\n",
    "    xlwriter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Bivariate stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file -- KHM_women_combined.csv -- has the following shape: Rows: 12592; Columns: 24\n"
     ]
    }
   ],
   "source": [
    "# Read in combined file\n",
    "df = read_csv_file(country, recode, file_type='combined')\n",
    "\n",
    "# Create updated bivariate variables (mother_edu_biv, eth_hoh_biv)\n",
    "df = create_bivariate_var_dep(df, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_dep and ind_var are: \n",
      " ['anc_4_visits'], ['residence']\n",
      "var_dep and ind_var are: \n",
      " ['anc_4_visits'], ['region']\n",
      "var_dep and ind_var are: \n",
      " ['anc_4_visits'], ['mother_edu_biv']\n",
      "var_dep and ind_var are: \n",
      " ['anc_4_visits'], ['wealth_q']\n",
      "var_dep and ind_var are: \n",
      " ['anc_4_visits'], ['elderly_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['anc_4_visits'], ['sex_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['anc_3_components'], ['residence']\n",
      "var_dep and ind_var are: \n",
      " ['anc_3_components'], ['region']\n",
      "var_dep and ind_var are: \n",
      " ['anc_3_components'], ['mother_edu_biv']\n",
      "var_dep and ind_var are: \n",
      " ['anc_3_components'], ['wealth_q']\n",
      "var_dep and ind_var are: \n",
      " ['anc_3_components'], ['elderly_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['anc_3_components'], ['sex_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['inst_delivery'], ['residence']\n",
      "var_dep and ind_var are: \n",
      " ['inst_delivery'], ['region']\n",
      "var_dep and ind_var are: \n",
      " ['inst_delivery'], ['mother_edu_biv']\n",
      "var_dep and ind_var are: \n",
      " ['inst_delivery'], ['wealth_q']\n",
      "var_dep and ind_var are: \n",
      " ['inst_delivery'], ['elderly_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['inst_delivery'], ['sex_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['caesarean_del'], ['residence']\n",
      "var_dep and ind_var are: \n",
      " ['caesarean_del'], ['region']\n",
      "var_dep and ind_var are: \n",
      " ['caesarean_del'], ['mother_edu_biv']\n",
      "var_dep and ind_var are: \n",
      " ['caesarean_del'], ['wealth_q']\n",
      "var_dep and ind_var are: \n",
      " ['caesarean_del'], ['elderly_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['caesarean_del'], ['sex_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['pnc_mother'], ['residence']\n",
      "var_dep and ind_var are: \n",
      " ['pnc_mother'], ['region']\n",
      "var_dep and ind_var are: \n",
      " ['pnc_mother'], ['mother_edu_biv']\n",
      "var_dep and ind_var are: \n",
      " ['pnc_mother'], ['wealth_q']\n",
      "var_dep and ind_var are: \n",
      " ['pnc_mother'], ['elderly_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['pnc_mother'], ['sex_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['low_bw'], ['residence']\n",
      "var_dep and ind_var are: \n",
      " ['low_bw'], ['region']\n",
      "var_dep and ind_var are: \n",
      " ['low_bw'], ['mother_edu_biv']\n",
      "var_dep and ind_var are: \n",
      " ['low_bw'], ['wealth_q']\n",
      "var_dep and ind_var are: \n",
      " ['low_bw'], ['elderly_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['low_bw'], ['sex_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['early_bf'], ['residence']\n",
      "var_dep and ind_var are: \n",
      " ['early_bf'], ['region']\n",
      "var_dep and ind_var are: \n",
      " ['early_bf'], ['mother_edu_biv']\n",
      "var_dep and ind_var are: \n",
      " ['early_bf'], ['wealth_q']\n",
      "var_dep and ind_var are: \n",
      " ['early_bf'], ['elderly_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['early_bf'], ['sex_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['iron_supp'], ['residence']\n",
      "var_dep and ind_var are: \n",
      " ['iron_supp'], ['region']\n",
      "var_dep and ind_var are: \n",
      " ['iron_supp'], ['mother_edu_biv']\n",
      "var_dep and ind_var are: \n",
      " ['iron_supp'], ['wealth_q']\n",
      "var_dep and ind_var are: \n",
      " ['iron_supp'], ['elderly_hoh']\n",
      "var_dep and ind_var are: \n",
      " ['iron_supp'], ['sex_hoh']\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "recode = 'women'\n",
    "var_dep_list = ['anc_4_visits', 'anc_3_components', 'inst_delivery', 'caesarean_del', 'pnc_mother', 'low_bw', 'early_bf', 'iron_supp'] \n",
    "\n",
    "ind_var_list = ['residence', 'region', 'mother_edu_biv', 'wealth_q', 'elderly_hoh', 'sex_hoh']\n",
    "\n",
    "# Run bivariate (extract WLS regression params)\n",
    "output = {var_dep: pd.DataFrame({ind_var: extract_regression_params(df, var_dep, ind_var, recode) for ind_var in ind_var_list}) for var_dep in var_dep_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate csv of outputs\n",
    "for var in var_dep_list:\n",
    "    fn = var + '.csv'\n",
    "    output[var].transpose().to_csv(f\"./output/bivariate/{recode}/{fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get bivariate differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file -- KHM_women_combined.csv -- has the following shape: Rows: 12592; Columns: 24\n"
     ]
    }
   ],
   "source": [
    "df = read_csv_file(country, recode, file_type='combined')\n",
    "\n",
    "df = create_bivariate_var_dep(df, country)\n",
    "\n",
    "var_dep_list = ['anc_4_visits', 'anc_3_components', 'inst_delivery', 'caesarean_del', 'pnc_mother', 'low_bw', 'early_bf', 'iron_supp'] \n",
    "\n",
    "ind_var_list = ['residence', 'region', 'mother_edu_biv', 'wealth_q', 'elderly_hoh', 'sex_hoh']\n",
    "\n",
    "\n",
    "for var in var_dep_list:\n",
    "\n",
    "    out_fn = var + \"_bivariate_diff\" + \".xlsx\"\n",
    "    path = Path.cwd() / 'output' / 'bivariate' / recode / out_fn\n",
    "\n",
    "    # Instantiate object\n",
    "    xlwriter = pd.ExcelWriter(path)\n",
    "\n",
    "    for ind_var in ind_var_list:\n",
    "\n",
    "        output = df.groupby(['Year', ind_var]).apply(mean_wt, var, wt=wt).unstack().transpose()\n",
    "        \n",
    "        sheet_name = str(ind_var) + '_weighted'\n",
    "        output.to_excel(xlwriter, sheet_name=sheet_name)\n",
    "\n",
    "    xlwriter.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1219f75a05e3de399f75b6a0fa3fc1e1cfa3d08777c7149c1fd01787d780976"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
